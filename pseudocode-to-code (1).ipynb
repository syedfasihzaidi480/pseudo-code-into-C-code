{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10860739,"sourceType":"datasetVersion","datasetId":6746733}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y torch torchtext torchvision\n!pip install torch==2.0.1 torchvision==0.15.2 torchtext==0.15.2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:25:49.547416Z","iopub.execute_input":"2025-02-26T17:25:49.547736Z","iopub.status.idle":"2025-02-26T17:26:13.188312Z","shell.execute_reply.started":"2025-02-26T17:25:49.547708Z","shell.execute_reply":"2025-02-26T17:26:13.187189Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.0.1\nUninstalling torch-2.0.1:\n  Successfully uninstalled torch-2.0.1\nFound existing installation: torchtext 0.15.2\nUninstalling torchtext-0.15.2:\n  Successfully uninstalled torchtext-0.15.2\nFound existing installation: torchvision 0.15.2\nUninstalling torchvision-0.15.2:\n  Successfully uninstalled torchvision-0.15.2\nCollecting torch==2.0.1\n  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\nCollecting torchvision==0.15.2\n  Using cached torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\nCollecting torchtext==0.15.2\n  Using cached torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.17.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (11.0.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (4.67.1)\nRequirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (0.6.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\nRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\nRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.3.0)\nRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.2)\nRequirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.15.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.15.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.15.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.15.2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.15.2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.15.2) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2025.1.31)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision==0.15.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision==0.15.2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.15.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision==0.15.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision==0.15.2) (2024.2.0)\nUsing cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\nUsing cached torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\nUsing cached torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\nInstalling collected packages: torch, torchvision, torchtext\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.5.0.post0 requires torch>=2.1.0, but you have torch 2.0.1 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-2.0.1 torchtext-0.15.2 torchvision-0.15.2\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport time\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tqdm import tqdm\nimport time\nimport torch.utils.data as data\nimport os\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:13.189709Z","iopub.execute_input":"2025-02-26T17:26:13.190050Z","iopub.status.idle":"2025-02-26T17:26:13.194870Z","shell.execute_reply.started":"2025-02-26T17:26:13.190007Z","shell.execute_reply":"2025-02-26T17:26:13.194054Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:13.196553Z","iopub.execute_input":"2025-02-26T17:26:13.196825Z","iopub.status.idle":"2025-02-26T17:26:13.211408Z","shell.execute_reply.started":"2025-02-26T17:26:13.196805Z","shell.execute_reply":"2025-02-26T17:26:13.210743Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Load dataset\nfile_path = \"/kaggle/input/spoc-train/spoc-train.tsv\"  # Update this if needed\ndf = pd.read_csv(file_path, sep='\\t')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:13.212555Z","iopub.execute_input":"2025-02-26T17:26:13.212794Z","iopub.status.idle":"2025-02-26T17:26:13.549941Z","shell.execute_reply.started":"2025-02-26T17:26:13.212775Z","shell.execute_reply":"2025-02-26T17:26:13.549054Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# Remove NaN values\ndf = df.dropna(subset=['text', 'code'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:13.551009Z","iopub.execute_input":"2025-02-26T17:26:13.551341Z","iopub.status.idle":"2025-02-26T17:26:13.613554Z","shell.execute_reply.started":"2025-02-26T17:26:13.551305Z","shell.execute_reply":"2025-02-26T17:26:13.612698Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Tokenizer (Basic)\ndef tokenize(text):\n    return text.lower().split()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:13.614484Z","iopub.execute_input":"2025-02-26T17:26:13.614795Z","iopub.status.idle":"2025-02-26T17:26:13.620624Z","shell.execute_reply.started":"2025-02-26T17:26:13.614764Z","shell.execute_reply":"2025-02-26T17:26:13.619002Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Build vocabulary\nclass Vocab:\n    def __init__(self, texts, min_freq=1):\n        self.word2idx = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n        self.idx2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\", \"<UNK>\"]\n        self.freqs = {}\n        \n        for text in texts:\n            for word in tokenize(text):\n                self.freqs[word] = self.freqs.get(word, 0) + 1\n                \n                if word not in self.word2idx and self.freqs[word] >= min_freq:\n                    self.word2idx[word] = len(self.idx2word)\n                    self.idx2word.append(word)\n        \n    def encode(self, text):\n        return [self.word2idx.get(word, self.word2idx[\"<UNK>\"]) for word in tokenize(text)] + [self.word2idx[\"<EOS>\"]]\n    \n    def decode(self, tokens):\n        return \" \".join([self.idx2word[token] for token in tokens if token > 2])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:13.621432Z","iopub.execute_input":"2025-02-26T17:26:13.621890Z","iopub.status.idle":"2025-02-26T17:26:13.639701Z","shell.execute_reply.started":"2025-02-26T17:26:13.621857Z","shell.execute_reply":"2025-02-26T17:26:13.639037Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Prepare vocabularies\nsource_vocab = Vocab(df['text'].tolist())\ntarget_vocab = Vocab(df['code'].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:13.641737Z","iopub.execute_input":"2025-02-26T17:26:13.641938Z","iopub.status.idle":"2025-02-26T17:26:14.493151Z","shell.execute_reply.started":"2025-02-26T17:26:13.641921Z","shell.execute_reply":"2025-02-26T17:26:14.492466Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# Dataset class\nclass CodeDataset(Dataset):\n    def __init__(self, df, source_vocab, target_vocab):\n        self.df = df\n        self.source_vocab = source_vocab\n        self.target_vocab = target_vocab\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        source = self.source_vocab.encode(self.df.iloc[idx]['text'])\n        target = self.target_vocab.encode(self.df.iloc[idx]['code'])\n        return torch.tensor(source), torch.tensor(target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:14.494451Z","iopub.execute_input":"2025-02-26T17:26:14.494671Z","iopub.status.idle":"2025-02-26T17:26:14.499384Z","shell.execute_reply.started":"2025-02-26T17:26:14.494653Z","shell.execute_reply":"2025-02-26T17:26:14.498572Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Collate function\ndef collate_fn(batch):\n    sources, targets = zip(*batch)\n    sources = pad_sequence(sources, padding_value=0, batch_first=True)\n    targets = pad_sequence(targets, padding_value=0, batch_first=True)\n    return sources, targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:14.500137Z","iopub.execute_input":"2025-02-26T17:26:14.500387Z","iopub.status.idle":"2025-02-26T17:26:14.514890Z","shell.execute_reply.started":"2025-02-26T17:26:14.500354Z","shell.execute_reply":"2025-02-26T17:26:14.514070Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# Create DataLoader\ndataset = CodeDataset(df, source_vocab, target_vocab)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:14.515817Z","iopub.execute_input":"2025-02-26T17:26:14.516093Z","iopub.status.idle":"2025-02-26T17:26:14.552674Z","shell.execute_reply.started":"2025-02-26T17:26:14.516072Z","shell.execute_reply":"2025-02-26T17:26:14.551917Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Transformer Model\nclass TransformerSeq2Seq(nn.Module):\n    def __init__(self, input_dim, output_dim, emb_dim=256, n_heads=8, ff_dim=512, num_layers=3, dropout=0.1):\n        super().__init__()\n        \n        self.encoder_embedding = nn.Embedding(input_dim, emb_dim)\n        self.decoder_embedding = nn.Embedding(output_dim, emb_dim)\n        \n        self.transformer = nn.Transformer(\n            d_model=emb_dim, nhead=n_heads, num_encoder_layers=num_layers,\n            num_decoder_layers=num_layers, dim_feedforward=ff_dim, dropout=dropout\n        )\n        \n        self.fc_out = nn.Linear(emb_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, src, tgt):\n        src = self.encoder_embedding(src).permute(1, 0, 2)\n        tgt = self.decoder_embedding(tgt).permute(1, 0, 2)\n        \n        output = self.transformer(src, tgt)\n        output = self.fc_out(output).permute(1, 0, 2)\n        \n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:14.553415Z","iopub.execute_input":"2025-02-26T17:26:14.553595Z","iopub.status.idle":"2025-02-26T17:26:14.568587Z","shell.execute_reply.started":"2025-02-26T17:26:14.553575Z","shell.execute_reply":"2025-02-26T17:26:14.567780Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# Model Setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = TransformerSeq2Seq(len(source_vocab.idx2word), len(target_vocab.idx2word)).to(device)\ncriterion = nn.CrossEntropyLoss(ignore_index=0)\noptimizer = optim.Adam(model.parameters(), lr=0.0005)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:14.569280Z","iopub.execute_input":"2025-02-26T17:26:14.569534Z","iopub.status.idle":"2025-02-26T17:26:14.891400Z","shell.execute_reply.started":"2025-02-26T17:26:14.569512Z","shell.execute_reply":"2025-02-26T17:26:14.890507Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Mixed Precision Training\nscaler = torch.cuda.amp.GradScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:14.892471Z","iopub.execute_input":"2025-02-26T17:26:14.892701Z","iopub.status.idle":"2025-02-26T17:26:14.896083Z","shell.execute_reply.started":"2025-02-26T17:26:14.892682Z","shell.execute_reply":"2025-02-26T17:26:14.895241Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"# Training Loop\ndef train(model, dataloader, criterion, optimizer, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        start_time = time.time()\n        epoch_loss = 0\n        \n        for src, tgt in tqdm(dataloader):\n            src, tgt = src.to(device), tgt.to(device)\n            optimizer.zero_grad()\n            \n            with torch.cuda.amp.autocast():\n                output = model(src, tgt[:, :-1])\n                output = output.reshape(-1, output.shape[-1])\n                tgt = tgt[:, 1:].reshape(-1)\n                loss = criterion(output, tgt)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            epoch_loss += loss.item()\n        \n        end_time = time.time()\n        print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader):.4f}, Time: {end_time - start_time:.2f}s\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:14.896974Z","iopub.execute_input":"2025-02-26T17:26:14.897250Z","iopub.status.idle":"2025-02-26T17:26:14.912174Z","shell.execute_reply.started":"2025-02-26T17:26:14.897229Z","shell.execute_reply":"2025-02-26T17:26:14.911376Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# Train model\ntrain(model, dataloader, criterion, optimizer, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T17:26:14.913109Z","iopub.execute_input":"2025-02-26T17:26:14.913399Z","iopub.status.idle":"2025-02-26T18:09:14.171064Z","shell.execute_reply.started":"2025-02-26T17:26:14.913367Z","shell.execute_reply":"2025-02-26T18:09:14.170250Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 6758/6758 [04:16<00:00, 26.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 1.3929, Time: 256.56s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6758/6758 [04:14<00:00, 26.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.7776, Time: 254.76s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6758/6758 [04:19<00:00, 26.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.6013, Time: 259.26s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6758/6758 [04:18<00:00, 26.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 0.5029, Time: 258.27s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6758/6758 [04:16<00:00, 26.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 0.4417, Time: 256.55s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6758/6758 [04:19<00:00, 26.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 0.4070, Time: 259.71s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6758/6758 [04:15<00:00, 26.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 0.3834, Time: 255.84s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6758/6758 [04:19<00:00, 26.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 0.3771, Time: 259.46s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6758/6758 [04:19<00:00, 26.06it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Loss: 0.3681, Time: 259.29s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"# Save model\nmodel_path = \"transformer_seq2seq.pth\"\ntorch.save(model.state_dict(), model_path)\nprint(\"Model saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T18:09:14.172067Z","iopub.execute_input":"2025-02-26T18:09:14.172293Z","iopub.status.idle":"2025-02-26T18:09:14.516042Z","shell.execute_reply.started":"2025-02-26T18:09:14.172274Z","shell.execute_reply":"2025-02-26T18:09:14.515287Z"}},"outputs":[{"name":"stdout","text":"Model saved!\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"# Optimized Code Generation (Inference) Function\ndef generate_code(model, input_text, source_vocab, target_vocab, max_length=50):\n    model.eval()  # Set model to evaluation mode\n    with torch.no_grad():\n        # Encode input text to token IDs\n        src_tokens = torch.tensor([source_vocab.encode(input_text)], device=device)\n\n        # Start decoding with <SOS> token\n        tgt_tokens = torch.tensor([[target_vocab.word2idx[\"<SOS>\"]]], device=device)\n\n        for _ in range(max_length):\n            # Get model output\n            output = model(src_tokens, tgt_tokens)\n            \n            # Get the last token prediction\n            next_token = output[:, -1, :].argmax(dim=-1).item()\n\n            # Append next token to sequence\n            tgt_tokens = torch.cat((tgt_tokens, torch.tensor([[next_token]], device=device)), dim=1)\n\n            # Stop decoding if <EOS> is generated\n            if next_token == target_vocab.word2idx[\"<EOS>\"]:\n                break\n\n        # Convert token IDs back to code string\n        generated_code = target_vocab.decode(tgt_tokens.squeeze().tolist())\n    \n    return generated_code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T18:09:14.516873Z","iopub.execute_input":"2025-02-26T18:09:14.517201Z","iopub.status.idle":"2025-02-26T18:09:14.522726Z","shell.execute_reply.started":"2025-02-26T18:09:14.517169Z","shell.execute_reply":"2025-02-26T18:09:14.522066Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# Test model with a sample input\nsample_input = \"create integer flag with flag = 1 \"\npredicted_output = generate_code(model, sample_input, source_vocab, target_vocab)\nprint(f\"Input: {sample_input}\\nGenerated Code:\\n{predicted_output}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T18:13:20.096197Z","iopub.execute_input":"2025-02-26T18:13:20.096525Z","iopub.status.idle":"2025-02-26T18:13:20.107060Z","shell.execute_reply.started":"2025-02-26T18:13:20.096499Z","shell.execute_reply":"2025-02-26T18:13:20.106304Z"}},"outputs":[{"name":"stdout","text":"Input: create integer flag with flag = 1 \nGenerated Code:\n\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}